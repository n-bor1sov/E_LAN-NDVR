{
 "cells": [
  {
   "cell_type": "code",
   "id": "cbcb8183b2bc3a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T02:28:45.771415Z",
     "start_time": "2024-09-29T02:28:45.768950Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "dd47ca5abdf83be3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T02:28:45.816540Z",
     "start_time": "2024-09-29T02:28:45.811354Z"
    }
   },
   "source": [
    "seed = 43\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    \"\"\"\n",
    "    Makes process of training more deterministic\n",
    "    and ables to get reproducible results\n",
    "    Arguments:\n",
    "        seed (int): Random seed to be used in fixing\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(seed)"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "419094752b80c87d",
   "metadata": {},
   "source": [
    "# Open embeddings"
   ]
  },
  {
   "cell_type": "code",
   "id": "b5fcd43fac8e9d40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T02:28:45.849985Z",
     "start_time": "2024-09-29T02:28:45.843236Z"
    }
   },
   "source": [
    "# Get uuids of existing videos\n",
    "existing_uuid = os.listdir('train_data_yappy/train_dataset/')\n",
    "existing_uuid += os.listdir('train_data_yappy/downloaded/')\n",
    "\n",
    "for i in range(len(existing_uuid)):\n",
    "    existing_uuid[i] = existing_uuid[i].replace('.mp4', '')\n",
    "existing_uuid = set(existing_uuid)"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "aa13eb04da800d9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T02:28:45.900080Z",
     "start_time": "2024-09-29T02:28:45.857952Z"
    }
   },
   "source": [
    "# Open dataset and remoce all videos that are not downloaded\n",
    "df = pd.read_csv('train_data_yappy/train.csv')\n",
    "df = df[df['uuid'].isin(existing_uuid)]\n",
    "df = df.sample(frac=1)\n",
    "df.reset_index(inplace=True)"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "9be38b3a7a2eed4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T02:28:48.350877Z",
     "start_time": "2024-09-29T02:28:45.900992Z"
    }
   },
   "source": [
    "video_uuids = df['uuid']\n",
    "video_uuids = video_uuids.apply(lambda x: x + '.mp4').tolist()\n",
    "\n",
    "root_dir = 'train_data_yappy'\n",
    "dataset_dir = 'train_dataset'\n",
    "\n",
    "# Load embeddings\n",
    "videos = []\n",
    "\n",
    "for name in tqdm(video_uuids):\n",
    "    full_emb_path = os.path.join(root_dir, 'emb', name.replace('.mp4', '.pt'))\n",
    "    video_emb = torch.load(str(full_emb_path))\n",
    "    videos.append(video_emb)  # Append video_emb to the list"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2500 [00:00<?, ?it/s]/tmp/ipykernel_98697/2206348839.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  video_emb = torch.load(str(full_emb_path))\n",
      "100%|██████████| 2500/2500 [00:02<00:00, 1048.75it/s]\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "id": "72a679f71f764665",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "id": "da7a07f7bae709e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T02:28:48.578624Z",
     "start_time": "2024-09-29T02:28:48.351744Z"
    }
   },
   "source": [
    "# Normalization of embeddings\n",
    "processed_videos = []\n",
    "\n",
    "for video in videos:\n",
    "    # Step 1: Average across frames (mean along the first dimension)\n",
    "    avg_emb = torch.mean(video, dim=0)\n",
    "\n",
    "    # Step 2: Zero-mean normalization (subtract the mean of the vector)\n",
    "    mean_value = torch.mean(avg_emb)\n",
    "    zero_mean_emb = avg_emb - mean_value\n",
    "\n",
    "    # Step 3: ℓ2-normalization (normalize by the L2 norm)\n",
    "    l2_norm = torch.norm(zero_mean_emb, p=2)\n",
    "    l2_normalized_emb = zero_mean_emb / l2_norm\n",
    "\n",
    "    # Store the processed vector\n",
    "    processed_videos.append(l2_normalized_emb)\n"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "1ebb7582cd48199f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T02:28:48.582523Z",
     "start_time": "2024-09-29T02:28:48.579814Z"
    }
   },
   "source": [
    "def uuid2idx(uuid: str) -> int:\n",
    "    \"\"\"\n",
    "    Getting index of a video in the dataframe via its uuid\n",
    "    Arguments:\n",
    "        uuid (str): uuid of the video\n",
    "    Returns:\n",
    "        index (int) Index of the passed video from the dataframe\n",
    "    \"\"\"\n",
    "    return df[df['uuid'] == uuid].index[0]"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "10d92a072d08c529",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T02:28:48.801921Z",
     "start_time": "2024-09-29T02:28:48.583263Z"
    }
   },
   "source": [
    "# Put indexes of original, duplicate and non-duplicate videos into lists\n",
    "dup_orig = []\n",
    "originals = []\n",
    "non_duplicates = []\n",
    "\n",
    "for i in range(len(processed_videos)):\n",
    "    if df.is_duplicate[i]:\n",
    "        # dup_orig[i][0] is a duplicate\n",
    "        # dup_orig[i][1] is the origin\n",
    "        dup_orig.append((i, uuid2idx(df.duplicate_for[i])))\n",
    "        originals.append(uuid2idx(df.duplicate_for[i]))\n",
    "    else:\n",
    "        non_duplicates.append(i)\n",
    "        \n",
    "# remove originals from non_duplicates\n",
    "non_duplicates = [i for i in non_duplicates if i not in originals]"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "abfaa0ab043869fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T02:28:48.807021Z",
     "start_time": "2024-09-29T02:28:48.802574Z"
    }
   },
   "source": [
    "# Split data on train and test parts\n",
    "train_originals, test_originals = train_test_split(originals, test_size=0.2, random_state=42, shuffle=False)\n",
    "train_dup_orig = [i for i in dup_orig if i[1] in train_originals]\n",
    "test_dup_orig = [i for i in dup_orig if i[1] in test_originals]\n",
    "\n",
    "train_non_duplicates, test_non_duplicates = train_test_split(non_duplicates, test_size=0.2, random_state=42, shuffle=True)"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "f6d89f038646f686",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T02:28:48.826114Z",
     "start_time": "2024-09-29T02:28:48.807695Z"
    }
   },
   "source": [
    "from typing import List\n",
    "\n",
    "# Create triplets\n",
    "def euclidean_distance(v1: torch.tensor, v2: torch.tensor) -> torch.tensor:\n",
    "    \"\"\"\n",
    "    Calculation of euclidian distance between v1 and v2\n",
    "    Arguments:\n",
    "        v1 (torch.tensor): First vector\n",
    "        v2 (torch.tensor): Second vector\n",
    "    Returns:\n",
    "        euclid_dist (torch.tensor) Calculated euclidian distance between two passed vectors\n",
    "    \"\"\"\n",
    "    return torch.norm(v1 - v2)\n",
    "\n",
    "# Actually we have to find such v-, that dist(origin, v-) < dist(origin, v+),\n",
    "# Where v- is non duplicate and v+ is duplicate.\n",
    "# However, our dataset is small, and we can concat all v- and original videos\n",
    "def find_closest_videos(origin: int, non_duplicates) -> List[int]:\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        origin (int): Index of a video to start search from\n",
    "        non_duplicates (List[int], numpy.array, or any iterable list with ints): List of indeces of non-duplicates videos\n",
    "\n",
    "    Returns:\n",
    "        results (List[int]): Indices of found videos with relatively small cos-distance\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    min_dist = float('inf')\n",
    "    min_id = 0\n",
    "    for i in non_duplicates:\n",
    "        # Find the minimum distance\n",
    "        if euclidean_distance(processed_videos[origin], processed_videos[i]) < min_dist:\n",
    "            min_dist = euclidean_distance(processed_videos[origin], processed_videos[i])\n",
    "            min_id = i\n",
    "        # Find the indicies with distance less than dist with v and v+\n",
    "        # if euclidean_distance(processed_videos[origin], processed_videos[i]) < euclidean_distance(processed_videos[origin], processed_videos[duplet]):\n",
    "        #     results.append(i)\n",
    "        results.append(i)\n",
    "    # If there is no such triplet, add at least one\n",
    "    if len(results) == 0:\n",
    "        results.append(min_id)\n",
    "        \n",
    "    return results\n",
    "\n",
    "def create_triplets(dup_orig, non_duplicates: List[int]):\n",
    "    \"\"\"\n",
    "    Creates triplets from list of pairs like \"duplicate-original\" and list of non-duplicates videos\n",
    "    Arguments:\n",
    "        dup_orig (List[(int, int)]): List of duplicate-original pairs\n",
    "        non_duplicates (List[int]): List of non-duplicate videos\n",
    "    Returns:\n",
    "        triplets (List[(int, int, int)]): List of generated triplets\n",
    "    \"\"\"\n",
    "    triplets = []\n",
    "    for duplet, origin in dup_orig:\n",
    "        results = find_closest_videos(origin, non_duplicates)\n",
    "        for result in results:\n",
    "            triplets.append((origin, duplet, result))\n",
    "    return triplets"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "45a16f381b5f4697",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T02:28:52.458364Z",
     "start_time": "2024-09-29T02:28:48.826746Z"
    }
   },
   "source": [
    "# Train and test triplets \n",
    "train_triplets = create_triplets(train_dup_orig, train_non_duplicates)\n",
    "test_triplets = create_triplets(test_dup_orig, test_non_duplicates)"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "id": "5a60973189dfca29",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "id": "a8303d81098993b1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T02:30:27.040845Z",
     "start_time": "2024-09-29T02:30:27.031305Z"
    }
   },
   "source": [
    "import torch.utils\n",
    "import torch.utils.data\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "# 1. Define a Triplet Dataset with Late Fusion\n",
    "class TripletDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dateset for storing triplets\n",
    "    \"\"\"\n",
    "    def __init__(self, data, processed_videos: List[torch.tensor], transform = None):\n",
    "        \"\"\"\n",
    "        Creates dataset\n",
    "        Arguments:\n",
    "            data (List[(int, int, int)]): List of (anchor, positive, negative) triplets\n",
    "            processed_videos (List[torch.tensor]): List of video data as sequences of frames\n",
    "            transform (torchvision.transform): transforms to apply on the data\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.processed_videos = processed_videos\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" \n",
    "        Gets triplet (anchor, positive, negative) by index\n",
    "        Arguments:\n",
    "            idx (int): Index to get triple by\n",
    "        Returns:\n",
    "            triplet ((torch.temsor, torch.tensor, torch.tensor)): Retrieved tripet\n",
    "        \"\"\"\n",
    "        # If late fusion is not used, use the raw triplet data\n",
    "        anchor, positive, negative = self.processed_videos[self.data[idx][0]], self.processed_videos[self.data[idx][1]], self.processed_videos[self.data[idx][2]]\n",
    "        if self.transform:\n",
    "            anchor = self.transform(anchor)\n",
    "            positive = self.transform(positive)\n",
    "            negative = self.transform(negative)\n",
    "        return anchor, positive, negative\n",
    "        \n",
    "\n",
    "# 2. Define a Simple Neural Network for Embedding Generation\n",
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(5488, 2500)  # Assuming input images are 28x28\n",
    "        self.fc2 = nn.Linear(2500, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 500)  # Output embedding of size 500\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  # Output embedding\n",
    "        x = F.normalize(x, p=2, dim=1)  # Normalize embeddings to have unit norm\n",
    "        return x\n",
    "\n",
    "# 3. Triplet Loss with Regularization (Custom)\n",
    "class CustomTripletLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0, lambda_reg=1e-3):\n",
    "        super(CustomTripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.triplet_loss = nn.TripletMarginLoss(margin=self.margin)\n",
    "\n",
    "    def forward(self, anchor, positive, negative, model_params):\n",
    "        # Compute the triplet loss\n",
    "        loss = self.triplet_loss(anchor, positive, negative)\n",
    "\n",
    "        # L2 regularization on model parameters\n",
    "        reg_loss = 0\n",
    "        for param in model_params:\n",
    "            reg_loss += torch.sum(param ** 2)\n",
    "\n",
    "        reg_loss = self.lambda_reg * reg_loss\n",
    "        total_loss = loss + reg_loss\n",
    "        return total_loss\n",
    "\n",
    "# 4. Model Forward Pass with Late Fusion (Average Pooling)\n",
    "class LateFusionModel(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(LateFusionModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "\n",
    "    def forward(self, frames):\n",
    "        # Process each frame independently\n",
    "        batch_size, num_frames, _, _ = frames.shape\n",
    "        frame_embeddings = []\n",
    "        for i in range(num_frames):\n",
    "            frame = frames[:, i, :, :]  # Extract each frame\n",
    "            embedding = self.base_model(frame)\n",
    "            frame_embeddings.append(embedding)\n",
    "\n",
    "        # Perform late fusion by averaging the embeddings of all frames\n",
    "        #fused_embedding = torch.stack(frame_embeddings, dim=1).mean(dim=1)\n",
    "        # averaging\n",
    "        fused_embedding = torch.mean(frame_embeddings, dim=0)\n",
    "        # zero mean\n",
    "        mean_value = torch.mean(fused_embedding)\n",
    "        zero_mean_emb = fused_embedding - mean_value\n",
    "        # l2\n",
    "        fused_embedding = torch.norm(fused_embedding, p=2)\n",
    "        fused_embedding = zero_mean_emb / fused_embedding\n",
    "        \n",
    "        return fused_embedding\n",
    "\n",
    "# 5. Training Loop\n",
    "def train_triplet_model(train_loader: torch.utils.data.DataLoader, model: nn.Module, optimizer: torch.optim, criterion: nn.Module, device: str = \"cpu\", num_epochs = 10):\n",
    "    \"\"\"\n",
    "    Trains model to encode videos to embeddings\n",
    "    Arguments:\n",
    "        train_loader (torch.utils.data.DataLoader): dataloader for training\n",
    "        model (nn.Module): model to train\n",
    "        optimizer (torch.optim) optimizer for training\n",
    "        criterion (nn.Module): loss function for optimization\n",
    "        num_epochs (int): number of epoch to train the model for\n",
    "        device (str): 'cuda' or 'cpu' depending on the machine and/or choice\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for batch_idx, (anchor, positive, negative) in enumerate(train_loader):\n",
    "            # Move data to the correct device\n",
    "            anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "            # Forward pass: Compute embeddings\n",
    "            anchor_emb = model(anchor)\n",
    "            positive_emb = model(positive)\n",
    "            negative_emb = model(negative)\n",
    "\n",
    "            # Compute the triplet loss with regularization\n",
    "            loss = criterion(anchor_emb, positive_emb, negative_emb, model.parameters())\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate batch loss\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss / len(train_loader):.6f}')\n"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "b8998c17e90cf12f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T02:31:24.497740Z",
     "start_time": "2024-09-29T02:30:27.483138Z"
    }
   },
   "source": [
    "# Open dataset and create dataloader\n",
    "train_dataset = TripletDataset(train_triplets, processed_videos)\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "\n",
    "# Initialize base model and late fusion model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model = EmbeddingNet().to(device)\n",
    "model = LateFusionModel(base_model).to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = CustomTripletLoss(margin=1.0, lambda_reg=1e-3)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Train the model\n",
    "train_triplet_model(train_loader, base_model, optimizer, criterion, num_epochs=2, device=device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Loss: 1.027908\n",
      "Epoch [2/2], Loss: 0.479768\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "id": "9bf21fd9dac6efce",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "id": "1e532d238759ef95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T02:31:25.234085Z",
     "start_time": "2024-09-29T02:31:25.231374Z"
    }
   },
   "source": [
    "test = test_originals + test_non_duplicates + [do[0] for do in test_dup_orig]\n",
    "\n",
    "# shuffle test\n",
    "random.shuffle(test)"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "3733da9e45c9d735",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T02:31:29.849323Z",
     "start_time": "2024-09-29T02:31:25.700682Z"
    }
   },
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "from qdrant_client.models import PointStruct\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Before oppening the connection, run the docker image of qdrand\n",
    "client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "# Delete the collection if it exists\n",
    "client.delete_collection('video')\n",
    "\n",
    "# Some parameters\n",
    "video_emb_dim = 500\n",
    "distance = Distance.EUCLID\n",
    "\n",
    "# Create collection (db)\n",
    "client.create_collection(\n",
    "    collection_name=\"video\",\n",
    "    vectors_config=VectorParams(size=video_emb_dim, distance=distance)\n",
    ")\n",
    "\n",
    "\n",
    "d = []\n",
    "# For each test video, find the closest video in the db.\n",
    "# If the similarity greater than threshold, then put the test video in the db\n",
    "# Else, we have found a duplicate\n",
    "for i in tqdm(test):\n",
    "    \n",
    "    v = base_model(processed_videos[i].unsqueeze(0).to(device)).detach().cpu().numpy()[0]\n",
    "    # search for the closest vector\n",
    "    search_result = client.query_points(\n",
    "        collection_name=\"video\",\n",
    "        query=v,\n",
    "        with_payload=True,\n",
    "        limit=5\n",
    "    ).points\n",
    "\n",
    "    # if the db is not empty\n",
    "    if len(search_result) > 0:\n",
    "        id1 = i\n",
    "        id2 = search_result[0].id\n",
    "        \n",
    "        if search_result[0].score < 0.59:\n",
    "            d.append((id1, id2))\n",
    "            continue\n",
    "\n",
    "    # if the db is empty then insert the vector\n",
    "    client.upsert(\n",
    "        collection_name=\"video\",\n",
    "        points=[PointStruct(id=int(i), vector=v, payload={'number': int(i), 'uuid': df.uuid[i], 'link': df.link[i]})]\n",
    "    )\n",
    "\n",
    "len(d)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 502/502 [00:03<00:00, 160.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "id": "b637f0ff5e871d2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T02:31:41.170930Z",
     "start_time": "2024-09-29T02:31:41.165867Z"
    }
   },
   "source": [
    "def metrics(d, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Calculates and prints precision, recall, and f1-score\n",
    "    Arguments:\n",
    "        d (List[(int, int)]): List of pairs of indices for detected video duplicates\n",
    "        df (pd.DataFrame): Dataframe with all the stored info about videos\n",
    "    \"\"\"\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for i, j in d:\n",
    "        if df.is_duplicate[i]:\n",
    "            if df.uuid[j] == df.duplicate_for[i]:\n",
    "                tp += 1\n",
    "        elif df.is_duplicate[j]:\n",
    "            if df.uuid[i] == df.duplicate_for[j]:\n",
    "                tp += 1\n",
    "                \n",
    "    fn = len(test_dup_orig) - tp\n",
    "\n",
    "    fp = len(d) - tp\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    print(tp)\n",
    "    print(f'Precision: {precision}\\nRecall: {recall}\\nF1: {f1}')\n",
    "\n",
    "metrics(d, df)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "Precision: 0.9125\n",
      "Recall: 0.9240506329113924\n",
      "F1: 0.9182389937106918\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "id": "aded9bdd14294a40",
   "metadata": {},
   "source": [
    "# for i, j in d:\n",
    "#     print(df.uuid[i], \"  | \",  df.uuid[j])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "73c870fc38bbfb70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T02:31:46.108882Z",
     "start_time": "2024-09-29T02:31:45.997652Z"
    }
   },
   "source": [
    "# save model\n",
    "torch.save(base_model.state_dict(), 'model94_59_base.pt')\n",
    "torch.save(model.state_dict(), 'model94_59.pt')"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "id": "722a121034b728a3",
   "metadata": {},
   "source": [
    "# TEST data"
   ]
  },
  {
   "cell_type": "code",
   "id": "589e106c0485a629",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T02:31:46.891438Z",
     "start_time": "2024-09-29T02:31:46.832410Z"
    }
   },
   "source": [
    "# load model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model.load_state_dict(torch.load('model94_59_base.pt', map_location=device))\n",
    "model.load_state_dict(torch.load('model94_59.pt', map_location=device))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_98697/1711451410.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  base_model.load_state_dict(torch.load('model94_59_base.pt', map_location=device))\n",
      "/tmp/ipykernel_98697/1711451410.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('model94_59.pt', map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "id": "ccb1ec1a33cec92d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T02:31:47.917867Z",
     "start_time": "2024-09-29T02:31:47.909126Z"
    }
   },
   "source": [
    "existing_uuid = os.listdir('test_data_yappy/test_dataset/')\n",
    "for i in range(len(existing_uuid)):\n",
    "    existing_uuid[i] = existing_uuid[i].replace('.mp4', '')\n",
    "\n",
    "existing_uuid = set(existing_uuid)\n",
    "\n",
    "df_test = pd.read_csv('test_data_yappy/test.csv')\n",
    "df_test = df_test[df_test['uuid'].isin(existing_uuid)]\n",
    "\n",
    "video_uuids = df_test['uuid']\n",
    "video_uuids = video_uuids.apply(lambda x: x + '.mp4').tolist()\n",
    "\n",
    "root_dir = 'test_data_yappy'\n",
    "dataset_dir = 'test_dataset'"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "id": "428868bd61e779af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T02:31:49.604344Z",
     "start_time": "2024-09-29T02:31:48.520655Z"
    }
   },
   "source": [
    "# Open embeddings \n",
    "videos = []\n",
    "\n",
    "for name in tqdm(video_uuids):\n",
    "    full_emb_path = os.path.join(root_dir, 'emb', name.replace('.mp4', '.pt'))\n",
    "    video_emb = torch.load(str(full_emb_path))\n",
    "    videos.append(video_emb)  # Append video_emb to the list"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/tmp/ipykernel_98697/1294434992.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  video_emb = torch.load(str(full_emb_path))\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 929.12it/s]\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "id": "4656af67472509ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T02:31:49.889125Z",
     "start_time": "2024-09-29T02:31:49.814561Z"
    }
   },
   "source": [
    "# Normalization\n",
    "processed_videos = []\n",
    "\n",
    "for video in videos:\n",
    "    # Step 1: Average across frames (mean along the first dimension)\n",
    "    avg_emb = torch.mean(video, dim=0)\n",
    "\n",
    "    # Step 2: Zero-mean normalization (subtract the mean of the vector)\n",
    "    mean_value = torch.mean(avg_emb)\n",
    "    zero_mean_emb = avg_emb - mean_value\n",
    "\n",
    "    # Step 3: ℓ2-normalization (normalize by the L2 norm)\n",
    "    l2_norm = torch.norm(zero_mean_emb, p=2)\n",
    "    l2_normalized_emb = zero_mean_emb / l2_norm\n",
    "\n",
    "    # Store the processed vector\n",
    "    processed_videos.append(l2_normalized_emb)"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "id": "dbfc2df1eba148d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T02:31:56.009823Z",
     "start_time": "2024-09-29T02:31:50.445104Z"
    }
   },
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "from qdrant_client.models import PointStruct\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "client.delete_collection('video')\n",
    "\n",
    "video_emb_dim = 500\n",
    "distance = Distance.EUCLID\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=\"video\",\n",
    "    vectors_config=VectorParams(size=video_emb_dim, distance=distance)\n",
    ")\n",
    "\n",
    "d = []\n",
    "\n",
    "for i in tqdm(range(len(df_test))):\n",
    "    v = base_model(processed_videos[i].unsqueeze(0).to(device)).detach().cpu().numpy()[0]\n",
    "    # search for the closest vector\n",
    "    search_result = client.query_points(\n",
    "        collection_name=\"video\",\n",
    "        query=v,\n",
    "        with_payload=True,\n",
    "        limit=5\n",
    "    ).points\n",
    "\n",
    "    # if the db is not empty\n",
    "    if len(search_result) > 0:\n",
    "        id1 = i\n",
    "        id2 = search_result[0].id\n",
    "        if search_result[0].score < 0.59:\n",
    "            \n",
    "            # check which video was uploaded earlier\n",
    "            time1 = datetime.strptime(df_test.created[id1], '%Y-%m-%d %H:%M:%S')\n",
    "            time2 = datetime.strptime(df_test.created[id2], '%Y-%m-%d %H:%M:%S')\n",
    "            # put ids in original-duplicate order\n",
    "            if time1 < time2:\n",
    "                d.append((id1, id2))\n",
    "            else:\n",
    "                d.append((id2, id1))\n",
    "            continue\n",
    "\n",
    "    # if the db is empty then insert the vector\n",
    "    client.upsert(\n",
    "        collection_name=\"video\",\n",
    "        points=[PointStruct(id=int(i), vector=v, payload={'number': int(i)})]\n",
    "    )\n",
    "\n",
    "len(d)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:05<00:00, 183.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "327"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "id": "e0c4c8eddc102049",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T02:31:56.020208Z",
     "start_time": "2024-09-29T02:31:56.011076Z"
    }
   },
   "source": [
    "for i, j in d:\n",
    "    print(df_test.uuid[i], \"  | \",  df_test.uuid[j])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4b005e08-6890-4c4b-b0cf-95dc3e1aabeb   |  fd52cbe5-012f-4451-abad-1c86c8279e8c\n",
      "22ee80a3-d9ef-48d4-83d7-9c97cc7030c2   |  6f6f5da8-f997-491d-8fe0-64d262b2ee4c\n",
      "045265e5-0d4c-4372-b960-3087f685eb97   |  cbf3948e-e8a0-4e61-858d-72b7ff2d2d43\n",
      "2cfd6af3-7df6-4afa-8c3b-c17236c83c03   |  89fca4ee-4678-482b-8d6d-907dbc057151\n",
      "0d62849b-d3b9-47af-a285-2f638bc9ac13   |  51b077bc-fac3-4cdb-bda4-06cd60d53af7\n",
      "0d21cfda-39e3-42b8-be97-aff5835036cc   |  7f3217c6-5a31-4b1c-a9f2-a8cb82e46ae3\n",
      "1c529118-dd4f-4c2d-a01a-1c5bf363ee4b   |  1eac74d7-40ff-4fad-9af1-4900da3e7c78\n",
      "7f90be99-fc5a-4503-9bef-4f6fbf70f47c   |  2ca7bcc4-eb59-4507-853a-5ff76179ecad\n",
      "49577a11-51b9-490a-b1f0-df17335219de   |  da9783ba-ceac-47ed-9d8f-30b614e938dd\n",
      "1c2de832-9df0-46fe-88bb-d125596fdae1   |  e846d78e-63e7-4136-b681-6452013e50dc\n",
      "42fbf1a0-2f00-4194-9733-675e19947a9e   |  edbacae6-1694-47f1-9abf-e6352acba998\n",
      "3a1d73a5-27a8-4f8d-8ec9-a129bb16cf32   |  eb129696-beb7-482e-926a-6152ac28d4bd\n",
      "3687b604-9481-4def-8b3e-7162c5546363   |  9791705f-d885-4c13-bb45-38f3d7620b05\n",
      "337fdbe6-2bc7-4bc7-931e-d94ada927ede   |  2cfe40dc-1cb3-4388-832d-4afcd3310f0b\n",
      "1d1ad7f0-7e04-4f6c-bea5-58ef8c5d2b4e   |  56fb847b-d57b-4043-926f-64769385f4a6\n",
      "7f90be99-fc5a-4503-9bef-4f6fbf70f47c   |  5ae075f8-399b-4cf0-820b-f8650b2e0858\n",
      "197b9b9a-172e-4ad0-b44e-fb78dde3c4b5   |  81f87ed8-fc69-4742-aac2-ec34b1f706f2\n",
      "049949e0-ad9d-49e0-9cc8-b311e4071f52   |  8526825a-e752-4910-8121-780e5fd3f9cd\n",
      "0628f10a-ca4a-4a24-90d0-b39dbd9cba47   |  ee4fc39e-3585-4f70-b5e7-4b64ef640ae1\n",
      "5150146c-2ebe-48f4-84ef-363d6fb73b5b   |  2bd7bc16-cf48-4700-8743-070e7c4636a4\n",
      "244edefe-81f2-4f17-9806-add1f934b776   |  80b8d5b4-3756-48d2-854c-c4df06aa768f\n",
      "83f6b958-34b5-4d15-973a-6e9dce4f3b59   |  0082f28a-16bb-4df7-9d74-7dd720d9547e\n",
      "2f160bfb-f3a4-4ce5-8525-e1537b666686   |  3c827d68-24ce-4e1d-87be-13b6472f3fa0\n",
      "35b038fd-0748-4f08-a001-434d18388f0d   |  8cf4856d-b085-4671-8065-e4c53cea21a7\n",
      "5317f402-8ef3-42c5-8133-cf559e32feab   |  607f4762-bf1b-4a06-89f9-7151e2356451\n",
      "1fbf64fa-d539-49f4-bcd6-1d2996453d2e   |  74d5c166-de57-48ef-9e58-05d6edaac9c5\n",
      "56ad43ff-5f8b-4f69-a710-544f0689c316   |  b3038c26-a6bc-4ef7-be6d-860758a00879\n",
      "31f0b3e9-2720-4cc8-b57b-bd7020af238e   |  d6e2ecf2-e25f-4404-aeff-f4322aa78dc3\n",
      "3e500c15-ffd4-4c74-92b0-dcad4bab92a9   |  d20b9af1-de0d-4461-9e62-f87264d7c74d\n",
      "14543718-8b24-4c8a-b21a-9a8420fa9557   |  85f14448-4f82-4d84-b91a-e3b2dee13254\n",
      "411f611a-0a94-429d-9bd6-3efcd66c0bb0   |  6af154b5-0e8c-40ae-b382-0f5ae0362e26\n",
      "204c815c-7a0b-409b-81ff-11c7b041c3bc   |  e6ec3fc7-24ad-423e-8ce9-745bbdc86985\n",
      "6dea4742-addb-49d0-8d94-46c9731d50ed   |  da0b8156-1fd2-4816-8d91-7470b74bf230\n",
      "1ecbf364-aa36-4d0e-9e1c-6bf4f6eccaf6   |  b1e1199d-58bd-4236-8541-454bb4920b76\n",
      "21422c01-5dd6-4299-b892-e4267454667a   |  8a7beeff-5fe6-4164-ab11-a1dc1fd55a1b\n",
      "161877d9-5769-4ee5-8be4-c4506862b2bc   |  ca330bcf-7297-432a-ad85-4c7eb4ab98fc\n",
      "154ef8f1-b0ce-49cb-b5b1-34d8f975875d   |  15e726c7-03cb-48c4-938c-7cd3e61bb987\n",
      "1e04d8a4-4bb2-4e2f-bc11-f6d10e136f71   |  a4acfb9f-7f2c-474e-81fa-f295814bcd7c\n",
      "110de471-9404-4ba7-8bae-eaceb1a2dc9e   |  e497cf28-d582-4e83-b7b3-2737efb39af3\n",
      "0e9cb9c3-a1f6-465a-83c0-9fe970147312   |  1235d8a1-efee-427f-97ba-84bdd99ef5c9\n",
      "3aad2ce3-bff3-416e-afe9-2db848c959bd   |  f41d2baf-756c-4ebf-9a7b-84d9a59ccca1\n",
      "2d9d01ee-e4cd-4ca0-9e45-eb194b45e9a6   |  0c3e7eb6-0ae5-4e0e-8c6a-355817e8706d\n",
      "123df5b5-b60a-4ad8-b7eb-bdc5c5a5216d   |  ee3129a2-52b5-43f0-997d-ed78b9f75e2b\n",
      "457dc40f-0bad-4fd3-8a64-3e984776d69f   |  408c83a2-1ed9-4dbe-9300-fc32cf4dccc5\n",
      "3aad2ce3-bff3-416e-afe9-2db848c959bd   |  6d8bc388-7f40-488f-a34b-69a9953c3bdc\n",
      "069d0eca-21e9-44ee-b44d-bc10099a2e21   |  6117e44d-9b5b-48c1-9868-2fadddc9d882\n",
      "3aad2ce3-bff3-416e-afe9-2db848c959bd   |  ea77c832-a4aa-4bf5-8c23-c38fd31baf0d\n",
      "03ed14a1-8a28-438a-8d4c-4e0ad01ba6bb   |  daaf47b2-5df3-4aed-a3b3-2143c3fe09f0\n",
      "502732c3-4692-4d1f-80c9-37177bb23ea9   |  e89668d5-f210-47ec-b900-323726e7ce49\n",
      "4bd8c353-c9f9-44e4-b385-6845823f78ac   |  366875f3-ec6b-4061-ad9c-f16a8d107aa7\n",
      "4a4d307c-e727-45e6-8d6e-ac14462d042c   |  27e9df78-4ec9-401f-8dec-cb6d3b409717\n",
      "1dfd5ee7-2488-4c21-a181-b719238197ce   |  09408e1e-b008-40b6-8571-2d9c0bf34f9f\n",
      "47d762d4-e65b-4981-8fe3-77af5f50d3ef   |  493273cc-08fb-412d-ae01-08423fe22c4d\n",
      "37de884d-ad88-47c6-aa27-e2b657d07f01   |  beffe154-0f5b-43c6-ba8e-14221233555c\n",
      "15f456ef-b474-4738-a4d7-fae4983685ec   |  55b0627e-69e3-42e7-8847-5967e19ae9d9\n",
      "55a0b6f3-8704-4f82-9864-3043188c6622   |  2dff09bf-6afc-48e4-9110-34c6bf90e926\n",
      "318bf238-5201-4980-82bc-b83f25353301   |  20a109be-7431-48fb-8264-8b05d975fbc9\n",
      "22d891cc-563a-48c9-9b6e-368829598e91   |  d4341c53-cb65-4fcc-8882-fe32ff34aa34\n",
      "0a63edfd-92bc-4a39-94c0-c46f1fb9dad8   |  d9060c03-304c-45c8-b3e6-417caf07f7a7\n",
      "0f8fd4bc-af83-46fc-92e6-29c59341d73d   |  7bdd1da5-7a07-4a7d-9ebe-c99a57a132fa\n",
      "1795ec11-e5aa-41e5-942e-9fb3aa1072fe   |  d59de777-7830-4232-95d0-cfac0e76a910\n",
      "44dac7ab-eabe-4d21-b541-9090c791485f   |  fbf2a578-c80e-4085-9c6d-9d171566b907\n",
      "6dea4742-addb-49d0-8d94-46c9731d50ed   |  34c583e4-125b-447b-8dde-7a91c3de34bc\n",
      "3919b7cf-f9e3-40c0-bde3-ab096ea022e0   |  065db773-887e-4216-a0f6-b19aa455db06\n",
      "35e3810c-eb1d-485f-a51a-3d4a39aa771b   |  5fe7168c-acb9-423c-8c7d-b043a1f99916\n",
      "c01492b4-b641-44be-b883-100510f335c6   |  c3f0536b-f31b-46da-a17e-ee5ee677e2ff\n",
      "2c68b7a9-8ab1-422f-886e-08e15fca56be   |  1d74a675-18a5-48f6-9652-4dfcb1c049bc\n",
      "7f90be99-fc5a-4503-9bef-4f6fbf70f47c   |  e1a6aaf0-fa52-46cc-b4b1-a8aabef1c8ea\n",
      "502a9fbe-62a1-4635-be0a-ee836692bb0d   |  9b3be281-f669-4e6e-adfa-f8eebc2ef3b3\n",
      "517d39e2-66c6-48f3-a8e4-f22b4de95f21   |  064c6912-7ff1-4808-b730-b90dbc618572\n",
      "49a8059f-46eb-4a14-80c0-50eae6524e18   |  4c42a54f-e505-419c-9f12-5cdc7d80284c\n",
      "3c39a845-8ca6-4134-93d2-b13a5b9f9a48   |  c8ef4da4-814b-4ede-bf03-2d9512564216\n",
      "0234d033-afb1-4ec4-add3-2fab9bf7914c   |  9d9b25ce-db76-48e2-9c3b-9a325695c4ce\n",
      "12866d01-fa3b-433d-acf8-f071323f5478   |  e80c87ba-d0b9-4588-880c-9c322cd0dca1\n",
      "07ca69ad-88fc-4ace-af79-5dcab60a4731   |  07f66195-9b27-4752-8468-2dca6dd6bc86\n",
      "122afbc7-875b-4faf-afef-54fcc8b5c22a   |  9c1d522e-8ee5-485f-8457-42223920cf26\n",
      "20fd148f-21f3-44a5-a0de-d210422820fe   |  b2342a15-1cdd-4dd8-bb18-050b8b29edcd\n",
      "2457d5e8-52e9-40a7-a5c8-85794a8d832c   |  c1b2e2bf-d18a-4185-97dd-83c1c792b75e\n",
      "31fc90bf-2255-4e7f-856d-2589b8ebbe2b   |  4bbd1f37-6983-4e3d-9c31-831f8b56ef9e\n",
      "34f786cd-67ce-4cef-a65f-1a21ebcf4021   |  024cba15-750c-4d19-9b71-797ad095f647\n",
      "493ade73-4c95-4d57-ba16-972337726825   |  c3cafd6c-e949-4c8a-9467-b5fd9bf30fcc\n",
      "4e82d954-ac77-4c71-ba54-7cce3f8fed16   |  0a8c8314-1e33-4ad2-9865-330df0ae79b6\n",
      "5540392b-705d-43a6-a277-c8fdd38ff418   |  84f7f9a5-df67-4e85-808b-93562e729e43\n",
      "07ca69ad-88fc-4ace-af79-5dcab60a4731   |  cfd0539c-fe11-4992-9e54-c5ae7b484be3\n",
      "51092a17-e84c-41c2-9cae-c6743ecb1789   |  f10d61cc-6f73-405c-9912-a162a69c50ed\n",
      "1e76b0e1-c747-4a2d-b02e-c083f78f01a4   |  2b2c4e7d-3354-4967-b4bb-ad7b9932e75b\n",
      "6dea4742-addb-49d0-8d94-46c9731d50ed   |  d31bba24-693a-4fe3-a854-84ae187299c4\n",
      "4125f588-58e0-451e-8939-95a412a01b50   |  28235d0d-5a41-4ead-a083-7b50d66c57b8\n",
      "0c2888de-3c0f-4cfb-ad14-a3eb6763d11e   |  8d2bfeae-87ae-4cd6-b581-d43b0068b44e\n",
      "02e00046-ca4c-43a9-a262-dd7c5cdf299c   |  e486df30-61d5-4923-91f8-fe03f55d6d65\n",
      "47cf16c1-1f46-462f-90fd-e547579d4c0c   |  1dd88001-7112-4e34-9a02-571afedd34de\n",
      "0feef7ae-1b28-40b2-ab4d-3730f2dcb213   |  07fa7255-9793-4e07-b9da-78a9abfd71a6\n",
      "242beefa-052f-42a0-bffe-53637bf62656   |  2e13c8e1-065f-4aa6-889a-643030e88336\n",
      "53d3cac2-2a34-4793-bef8-7d1bae69998c   |  831515a3-d267-4fbb-a696-6de492d906f9\n",
      "32da7a2a-dd20-4672-8ce8-b51ab21ebc5d   |  980b8db7-3290-4e39-a841-23d0fc0b2ae1\n",
      "4aeaba33-dbfb-41b3-ade0-b06a87824f1c   |  d02dca26-1696-4c96-b63c-bf348d245cd8\n",
      "0fe61af5-de49-497b-9194-78e6322e10e5   |  00357913-2cad-4389-9bc6-a10c26f15679\n",
      "3d51898f-1321-4a03-95a2-2f8cfb6e03bd   |  008e8b3a-8ee5-4ddf-b1ba-b8657541d5c2\n",
      "4831d29a-7c13-4d0e-843f-ed63f0a57589   |  7a09f87d-1f13-4c40-ab4b-0b109c0dfb42\n",
      "0aede0b8-f305-4523-b8d5-0daae970bffb   |  4e99863b-4c4c-44cd-8156-1448e0e0e64f\n",
      "42672f48-f492-40ca-b44a-6afd6060fb99   |  783c5b0f-1293-40d3-a11e-6df72c1cc685\n",
      "435a628b-dd06-4b47-ba4a-ebd3e50301c3   |  db1bee9c-449b-471c-a0e6-800c6e875b62\n",
      "31fc90bf-2255-4e7f-856d-2589b8ebbe2b   |  d8276034-b33a-4c32-8969-eb396fd990e6\n",
      "3a2ea8fe-ffcc-4531-95f3-1a90acd73de6   |  7aa8ec6d-185f-40e9-93f5-d038aacd6ec0\n",
      "257029be-d6bf-4d6c-9033-297df8a3bdd7   |  20aa749a-96f5-486a-bbe7-d7f00775fb0d\n",
      "17b3b6d8-020f-4388-b40e-fdcac7640381   |  b9f26d66-1f66-4a98-a23c-931038bbba48\n",
      "c01492b4-b641-44be-b883-100510f335c6   |  7f6ae19b-e348-4aa0-adfc-6b2de50f64bc\n",
      "33dbd76d-6320-4a0e-a690-3b4e41f22af6   |  d29f91fa-ce6d-4325-8546-7e6eefd4d1d8\n",
      "21becaf5-b4fc-4427-b952-edc43b8a385b   |  4ddd8001-78de-47a1-86ae-213dd67d7d0e\n",
      "0b01849a-cb73-47e1-ab3f-7d82cdfa34b5   |  36f2c6b5-cc2d-4e29-bfb2-abe406cc68dd\n",
      "2b00d0c4-a554-466e-917c-bbb8c7c2e509   |  764403f2-cd65-48f2-b65c-2d05dea18fe2\n",
      "01037207-0047-4925-a585-f6bb8c511c90   |  d6944f81-d843-41f2-85a9-65815e54fa15\n",
      "1c65000c-a581-40eb-8899-ae5f3429d8f3   |  72609dd2-d3e6-4ca1-b203-29ebdb3371ce\n",
      "5540392b-705d-43a6-a277-c8fdd38ff418   |  35e6611c-adcb-473a-91d0-7205dd99c327\n",
      "3723398a-4df2-4a7d-a466-9f41b7dcbced   |  0da84c23-77f4-40b5-adf5-b1095f091a47\n",
      "3aad2ce3-bff3-416e-afe9-2db848c959bd   |  828311dc-cede-4506-a710-0e475ebc5429\n",
      "27aab75c-7f03-4739-9731-cd1bb82a2ec2   |  05155a2c-4aca-4644-b9c1-4495e5925c59\n",
      "3b5202eb-b60a-4c4d-a001-a3594be6e873   |  8a202ba1-d9c1-41ff-89ba-22c0685ccb89\n",
      "832cba7f-ac59-4cc5-ad4b-91f99775ca96   |  8f64d59c-6f21-4f03-97e4-dbd429b6c157\n",
      "241d7aea-8d30-4995-bbba-03fb42746f1b   |  31ba16aa-e6de-456b-93d1-1188ac188ffe\n",
      "01c23a9b-1431-4110-a073-82f78761cdf4   |  1a79ebc6-7db2-4b2b-86d0-06362cbbf534\n",
      "09d5d9a7-0199-49c4-abff-283a6898468f   |  92244114-1e11-4f84-8570-9867347d5473\n",
      "067b64d8-0f83-45ff-b395-a83dffbd660f   |  6bad0265-5fd2-4de2-9581-1a3e895f0f36\n",
      "39e23599-d4e9-4569-8999-ce8de1056509   |  3e542e42-fbc5-41a3-9273-e7e9aa2d5a9c\n",
      "c01492b4-b641-44be-b883-100510f335c6   |  d432b27a-cf1e-4e67-853c-292db6f132c6\n",
      "1deedd92-884e-4d0a-9742-d1e5118ec3c0   |  ce550f6c-4c17-4798-af15-322210ee9de2\n",
      "03f7df91-e272-4163-a118-73a32e958c68   |  e2240143-69b5-4c79-8fe3-80d17d5c6015\n",
      "52b43ae1-e607-4210-828e-977f71e3d6b8   |  4d13d787-e3ba-4bbf-b697-e3a91a54ac8b\n",
      "440c69ad-8a95-4b16-8a77-d2696f1be778   |  7ab0c75d-3995-4bab-b1e2-a0c83a8389b1\n",
      "33dbd76d-6320-4a0e-a690-3b4e41f22af6   |  6c1eb6f9-82fd-4091-b73f-4e46b03541f8\n",
      "3aad2ce3-bff3-416e-afe9-2db848c959bd   |  c663363d-29d1-437c-891c-5d93185e8d61\n",
      "3b647584-ce8c-4757-8dda-6d442be8ed72   |  c94a0ddd-ecdd-4b1d-9598-b37e93d24f58\n",
      "47ce404d-123e-4cc5-b521-ad203c90299d   |  4d4a8f94-cf04-40f5-b68b-1a4f8b2663c5\n",
      "5649bcac-fb03-41a7-8211-c3af8a40dca1   |  1ac6f950-916c-4e5b-b2e5-ae9d4f14852c\n",
      "3aad2ce3-bff3-416e-afe9-2db848c959bd   |  2b5fa967-ccab-4a13-8344-800f01fb3d67\n",
      "83f6b958-34b5-4d15-973a-6e9dce4f3b59   |  9a22bf9b-496c-47ac-ac0f-7f856975926f\n",
      "c01492b4-b641-44be-b883-100510f335c6   |  22f5aed5-5caa-4d5c-97b4-26863e749055\n",
      "3bd97009-78e7-48bb-a907-486e0bb3d700   |  9487de98-2ac9-4b49-9ce0-280aefbea012\n",
      "03480797-7120-4f7a-833d-b30264ee2420   |  33d2e8f8-e860-439a-ab69-7be148b695d8\n",
      "55579213-9c71-4c28-8fc0-cd3895c00002   |  16370e32-3b24-47ae-b0ab-779e42becc44\n",
      "507c2679-fd14-4a4b-9bb8-d5ad6cbb1837   |  7b55554b-80ae-4d00-b551-ad90b2d82dd2\n",
      "831a1359-1063-475b-88dd-36228b17fb69   |  8f51b2d1-13be-44b7-97c1-4173a862f11c\n",
      "2568727f-de58-4dc8-9c0a-5b89435e36af   |  6aef6662-5d3f-41f1-bd63-a19fc14668f2\n",
      "16505c0c-92d0-4386-901c-bf9693541ecc   |  a22cea67-c7c6-4780-86a7-298a604c706a\n",
      "273aa05c-c878-42ce-a260-d843fe330eea   |  18e4ab84-e35b-4757-9b7f-846095a5c09e\n",
      "5540392b-705d-43a6-a277-c8fdd38ff418   |  8321b136-0e3d-4e01-88d7-ce168fc330e0\n",
      "176f8503-9213-4b34-a048-1e752a8ca7a5   |  c01c0da8-fc1d-4707-aad5-e3277e0a2708\n",
      "1162e54d-404f-4c61-b5cc-83dc1368224f   |  db3db912-3c8a-4392-aa6b-f8edbf33dc2b\n",
      "2b97f0d0-9403-4a8c-8233-a7d510b0d002   |  c97f942d-a045-45fc-a74a-f43d43dd1487\n",
      "34840f48-e1e1-48da-9555-6bbafc9651e2   |  b509e154-64ce-4e72-a889-fa841e00c1b7\n",
      "45569cf8-38d1-4594-8641-5f772dac6a72   |  2a2a2f0a-c662-42f2-9a0f-2a6df0ee1879\n",
      "2c1e9a87-2e2e-46bc-b78e-f022003c6337   |  5eb3ddca-8914-4691-91e6-e16f2685a0f0\n",
      "82f63b20-1671-4b64-a339-51c7dfa61518   |  82bb6a72-90a2-4729-901e-8b7c4e4e434e\n",
      "3d80a2f4-fcf1-4782-a5d4-d84fcc3361c9   |  0834c368-69bb-4981-8f7b-d9ef377e20ab\n",
      "32f1ba7e-879c-46a2-b572-40437a9c9d74   |  3fa57fa2-0a72-457d-a472-b9ceb3d7a3eb\n",
      "3df403d8-0341-4241-a2fd-25ea139aed7c   |  e97fd255-4cf5-4598-bd3f-f8675611a258\n",
      "5540392b-705d-43a6-a277-c8fdd38ff418   |  21382015-30d3-40c0-85f2-b0867aed08d5\n",
      "4cdb5497-8348-49b6-ba48-deb5d5315704   |  f2b2bfa6-8085-4bb9-b76d-421814e83436\n",
      "5540392b-705d-43a6-a277-c8fdd38ff418   |  bdf667a8-bc40-44c7-9373-ca5111f6dac3\n",
      "53aec1a3-f36d-4aee-b1fa-b8986507411b   |  3a4f7d2f-a7ad-4439-8ab9-bd5b83c5fc60\n",
      "2cc6825e-22f1-4f91-8831-f5ce6e796799   |  1db82449-5cd6-46b7-bb6c-b02013f72c15\n",
      "5732d2e1-efc8-4b66-bd3b-25fc0fc78c47   |  1f387924-7aaa-4ea5-afd1-1ce1d3939154\n",
      "16ca39f7-3756-4b6a-8c3c-d09b4ed72745   |  2eaea521-2714-43c6-a871-216fa6cf76ab\n",
      "22fd9d61-86ff-4233-a4e6-2a19ef8cd156   |  34cca950-8e93-4bd1-a7e8-b1ad1c062f91\n",
      "6dea4742-addb-49d0-8d94-46c9731d50ed   |  1b031829-aa77-491e-a0ac-83774dd466e5\n",
      "10c29e82-b992-4a56-a342-99b04044a303   |  b704ed25-20c0-46ef-9dde-ba8a1ab3a1f5\n",
      "1418fd4e-782b-444a-a53c-52b2b11c9c3b   |  dfecea09-3ba7-40a1-8e45-150ad0fd7476\n",
      "17dab99e-753d-4322-9131-5cfabf8bd685   |  da356f1f-dc21-4e60-ad50-b3ca180b3e1f\n",
      "56b9d391-e8f2-4f6a-9964-c767b94f7d0a   |  2df86b86-c9f6-40fe-9822-082ef0cb0f4c\n",
      "0c246a8d-6558-4115-9ccc-c374b9f18734   |  dc2ca095-e1a0-4814-962a-28db24aa0f28\n",
      "4fbbfca7-70c1-44dd-9ff8-71d4fb98df69   |  e2230a43-b76a-48eb-b75d-39d823f4885c\n",
      "19829653-adba-4897-9fbc-8b801d3bd34d   |  784c238f-cbd2-4589-bdc6-fb438869e309\n",
      "bcc15b9e-6311-4d39-808b-da97bd803fb3   |  3889d844-5c8f-4de5-92be-efe7147fb663\n",
      "21becaf5-b4fc-4427-b952-edc43b8a385b   |  47ab432b-c187-426f-8502-fbb92ae8ba1d\n",
      "18309d75-02d6-4c8b-bf6a-3e80c19d66df   |  64f26761-de85-447d-9fa5-58198a64331b\n",
      "0d02bec0-60c8-48d5-a538-397f7d66cad1   |  29a8555c-cb23-4067-8b83-ae4125a89242\n",
      "8337a7ed-4be2-47f3-938e-6b7078bc84b6   |  f005d79a-315e-43b2-bd32-ed267ef12ed7\n",
      "01d7830d-6f60-4bb3-8c85-8d8c91f38ba0   |  e656a520-7052-49ee-a247-15ec218ac561\n",
      "11a1de0b-3bcc-47fb-a2c7-946c3eec72a5   |  51699228-c0ca-4003-a88d-de204e4196a8\n",
      "27c17fe0-ea06-4a2c-a206-c399b4c34b8d   |  4c3a801c-5479-4a3c-8a08-b71b96fa18e5\n",
      "54c217c5-660e-4eb2-a5ce-49f06c5f554d   |  699e9621-cdd6-4724-bd3e-d2f13b123992\n",
      "59458518-ab8b-4fac-8936-4e31bbca5dd3   |  a19053f8-83ad-4142-bd4f-9d6506ba5f5b\n",
      "3aad2ce3-bff3-416e-afe9-2db848c959bd   |  82f765e4-ff8f-45b8-94a5-2caa15e29095\n",
      "c01492b4-b641-44be-b883-100510f335c6   |  c2dd05b2-a2fa-427a-8d44-180023f10666\n",
      "189023f8-3db5-466e-947d-856c3d1c5380   |  4e3fee1c-9ed4-4feb-a732-3426d00cc051\n",
      "524f8656-efc3-4ddf-b618-26962077df8c   |  1997f3af-887a-45f7-be4d-1183d854ca6a\n",
      "c01492b4-b641-44be-b883-100510f335c6   |  2a732af0-d15a-4ed2-bfd0-8e083e6932d8\n",
      "3e0b8fc6-f84f-4397-afdb-20261e516b0f   |  786c74b5-566f-481a-bf6c-54d3ea12f527\n",
      "3aad2ce3-bff3-416e-afe9-2db848c959bd   |  b6bca588-408c-41ae-a112-dbcedb0de3b1\n",
      "1b55f595-7724-49b7-8e89-e61b894e7afd   |  b50abc43-684d-4caa-9ad4-83da17def41d\n",
      "4dfe01c9-2b4a-4ae8-8d0a-f26864dbbbf2   |  f8ce8ce4-4f1b-44a9-85e4-3b67b9345178\n",
      "1c572c7e-b08a-4086-b6fc-67b9b43de0ad   |  691c3efd-a56d-4e7b-a9b0-d720a751ab25\n",
      "0ef64e5f-7096-4e4b-b896-b09eb9f3f120   |  855360ff-d99c-4e30-9c6a-506edd2e3624\n",
      "132ba88f-4c97-4c59-8cd5-3994ea9a0fa4   |  6373cf09-7b9d-4a3d-85df-c0b423bfda3b\n",
      "334f9a6b-e2fe-48d2-98d9-0024187a0d69   |  d3faab80-40ce-47d3-807f-3cfcd5b11615\n",
      "5540392b-705d-43a6-a277-c8fdd38ff418   |  27d77326-fd06-49e5-9263-fc3d4d5615bb\n",
      "7f90be99-fc5a-4503-9bef-4f6fbf70f47c   |  40d0e3d4-bcf5-47d4-9070-579111c751f0\n",
      "442ed9cb-cd31-40a5-95d0-f450d79915ee   |  b0417db8-0c92-4994-8359-e9e1f1c2720e\n",
      "6dea4742-addb-49d0-8d94-46c9731d50ed   |  af7ac9b9-b15b-45fb-a9f5-4c331856ed6e\n",
      "4150e48f-f9ad-47fe-84de-89e9e2018536   |  3d91d268-7e3a-406e-a23a-38af0bb64d62\n",
      "3aa816a4-a019-44ff-aafe-a471765fa07a   |  b901e4d6-f748-46e4-afaf-f78d52a46356\n",
      "22d57e95-70b3-470a-9f79-1fe42dbed75d   |  6f119dea-ff57-45af-910b-0ed7ba1ddb40\n",
      "31c63838-de1f-44a3-9239-aff1f365d553   |  470c031f-ef07-427c-93a9-e230ec5305b3\n",
      "8319aece-4d91-419b-9501-cfc9b05abf11   |  a6ded8c7-2654-430d-9468-208e6d76cc55\n",
      "2d5fe4ac-711a-4b85-aece-e6dd135e560b   |  297856cc-de33-44c4-afc0-493198a74e3c\n",
      "02946cdf-31eb-48d1-8dec-960f47d75e9f   |  84eec6b7-d741-45aa-953e-2c0f7c732141\n",
      "26e62e19-9c98-409b-b441-cd5504d46093   |  34ccc284-f38a-4dab-b5f5-074da6e4fa3b\n",
      "339ba78f-82b8-4f24-9422-f7c932560026   |  7b7ea8f5-632b-47a9-aa47-6b7b269a9b6a\n",
      "2b75742e-eecd-48b7-81b8-5c0d536043e9   |  e6d7447f-4f4a-4d47-9445-40344d3ed5e0\n",
      "50de0457-2a74-4e7d-b670-a1b5552c0c52   |  bcd4ab87-9ecb-4551-b61f-b3a0f4521451\n",
      "4807b026-dec0-4f84-86b1-8217ce430c75   |  90ecfd29-173b-4452-8473-a62536db838d\n",
      "1621a984-c934-40e8-9031-7ada01d651a0   |  13ff00c5-95ca-4e6a-b603-73f3644430c4\n",
      "2ef63356-39a0-4f27-afb9-274660c515ca   |  e866c207-3dec-494d-8dc5-5f7999e65d6b\n",
      "3aad2ce3-bff3-416e-afe9-2db848c959bd   |  df91d39a-0d1e-4d98-b316-0902c805e20d\n",
      "44e8163b-199f-4335-af69-e25c7209520b   |  1429f728-19ec-4d25-bcc3-0b7e40075e85\n",
      "36e805d1-f183-45b6-a911-a205cab14256   |  4b38e3b3-de10-4fc0-a60e-97ed3890050d\n",
      "2d9c00e3-4f78-4eeb-be2b-cf13031c1896   |  aed7d0d2-e5ab-4270-83f3-d9b2bdf5b8b6\n",
      "4c4e8c7b-8c1b-45ef-9133-4f35920072d1   |  484a1dde-51aa-4dc0-81f4-a520a905ad43\n",
      "3aad2ce3-bff3-416e-afe9-2db848c959bd   |  d74895c9-8e4f-4af4-b9f1-812747beb690\n",
      "46875911-1856-41e4-8a48-c0e7d223ab85   |  35392bb0-7e28-41a6-a501-3c93a901841d\n",
      "bcc15b9e-6311-4d39-808b-da97bd803fb3   |  8f9bacc2-519b-463e-9170-604f9b9780d0\n",
      "36d3e564-58ea-4988-b9ad-62b162d0e6f3   |  f9c027a6-7eb2-470a-bb93-72f7e5dcb7e3\n",
      "498850c3-736b-41f5-8cb4-892079f65595   |  f48e7d78-d582-4146-869c-963848bdce7f\n",
      "50a257ca-93a5-4126-a6c3-a743db0ebd84   |  2bae54d6-6b46-43c4-838f-33254479a332\n",
      "43642a38-860f-41c3-9815-7a2ae5fb4ae6   |  7d212f0c-52ae-4216-a0f7-7c011107072d\n",
      "013d4a72-1258-48e4-813e-ceba459ac5bd   |  73c26250-6b68-4f08-9725-007b03627f3f\n",
      "0a6188fc-9854-4029-810d-5ba61f544154   |  3cd60e16-251c-4d05-9ef5-5632dbd068a3\n",
      "39562846-1311-430a-a1bd-a65269cab7a0   |  1e537a77-3963-42ac-97be-9a13f4f38883\n",
      "157203b7-ed05-4834-b29b-1d713d563988   |  253702b3-eca7-48ec-b8b4-f1dc972c925b\n",
      "419d30cf-ccaa-46d1-87c0-22c12ac08fc9   |  caaacf91-da80-4723-987c-1f9042a7dd93\n",
      "82ebe502-9a5b-4c82-8aa3-38af67860ca2   |  4f0ee895-5ee0-4a6f-b96f-f2be2616ccf4\n",
      "44682ca5-e28a-43e6-952b-bef897b68e02   |  86be37ed-935e-47ef-bde8-0897e0b0449e\n",
      "0e7428b9-f429-46f3-b244-38353c90f30d   |  8314164d-f905-4729-b956-5fb3672fdf81\n",
      "210899a8-7557-47b8-937e-7a69c1417ef7   |  c9086a6e-dddd-490e-aaf6-5ab68c753eae\n",
      "21d52828-0be8-49a4-915b-fb1c7a7c1075   |  8d718fa1-9c05-484a-bef6-87daaeaf1805\n",
      "3e71f2a3-1d38-419b-9e36-737b56d65a09   |  fc85f2f3-225a-4353-a897-ef5b1f73bffd\n",
      "08762a09-aa5b-434a-b892-b7e3a537e7ef   |  c3594ef3-5f4f-4a2f-ab8e-0f075781d70b\n",
      "bcc15b9e-6311-4d39-808b-da97bd803fb3   |  94859234-c079-47ba-9adc-9ff0c7cc30f5\n",
      "406baceb-9224-4645-ab16-4e6dac9587d0   |  162d0ca5-9f74-434f-98b0-055ed56c7dff\n",
      "7f90be99-fc5a-4503-9bef-4f6fbf70f47c   |  58800189-4783-4419-b39a-6372cab971ce\n",
      "216bfa02-b989-4ea4-a73a-b03e32c2d6e2   |  e32560b7-0abb-4111-a226-f7355d62fbd2\n",
      "07e58009-9485-4c74-996b-3f18be09cb77   |  35d4dee7-37e4-46d1-8771-e1dbb87aa2a9\n",
      "4689fad9-c05a-4d17-8936-0cf59abfbed3   |  34166a2e-789c-4d0e-9998-49d530e7076f\n",
      "3df1b57b-5477-411d-a350-d2ef289276a4   |  3ca7725a-c2a8-4703-96e6-ba21a6d10105\n",
      "2b61d26f-622f-4da1-83f3-fb20a5bf491c   |  aad18774-49b1-4651-8703-51fc2574fff9\n",
      "f6bb9756-88ac-413c-a284-e45d1c79589d   |  5204cd6b-9daa-4265-98e7-138865847aba\n",
      "571ecbfa-c2ea-4490-ae00-c07bf0203c2d   |  4acb74f3-8e8c-47b7-bd63-b2bfbbf2f560\n",
      "4b6374ca-fdd5-4b7f-b406-f95beda4e5ca   |  e8224a68-6afb-42ae-aeb9-13077ab5ef5d\n",
      "2b9cdb5b-ea38-4d34-b73b-712cc4589fbd   |  305a592c-b704-477d-b88b-3eba333412d5\n",
      "574e5d21-bc82-4a2e-81cc-d0ee8e5e9312   |  d28c8a2a-0170-46ac-8d0f-f5744a3e03a4\n",
      "1ee92e52-1744-48d2-9771-8c3db6d6ffde   |  4bcd9a5c-9bd5-463f-924d-e9832a96e5bc\n",
      "2ffdb6b8-145a-4051-89ea-5454acb59bd7   |  e5d8335f-5f14-44fe-903e-30fdee1b8c53\n",
      "39562846-1311-430a-a1bd-a65269cab7a0   |  ca8f283f-0e98-4067-b3b1-8a453772ea45\n",
      "3f64e6f4-c205-48e0-8574-fbf4af97f702   |  6dc603d0-30f7-4bcb-a28a-32c5c81d9f5e\n",
      "2b3258a0-4e9b-4900-a7f7-2bfd779d6f17   |  0243a61c-bb86-4aa1-b671-3d82811348eb\n",
      "07ac9a99-a298-48ff-ae8f-c04e192bd015   |  24f9066d-35f6-4b76-b0a5-f214002c6c17\n",
      "4cd6adb0-2936-4d31-8a0e-10f51b3efdd3   |  9dfafa15-8c57-47e1-a5c2-c8f8ce462d2b\n",
      "332b4555-1db8-4b5d-a54f-c6546ffda043   |  9eaa28f1-b44a-4d39-8b0a-d3506801b5df\n",
      "5540392b-705d-43a6-a277-c8fdd38ff418   |  afd7f5e9-f66a-4720-be53-7c20ff78d8de\n",
      "219e9f82-f261-4c95-87c0-56b4b84bef60   |  4d9eca4f-3292-47fc-b8c1-4b1265d2a6d5\n",
      "43a4f55f-1762-4899-be96-38f36c3c4ecc   |  bbf5690f-f4d6-40f6-a7d4-184fe6e75b3c\n",
      "1063027a-dd7f-42e5-b3f7-e82bdc9f9c41   |  f49f9c64-5a71-4800-8898-9dd2ddb8a5f3\n",
      "021963d9-5ef2-476a-97d3-0c4b05113d08   |  ce21b5bb-3fe5-429f-8b2d-cd27cea863a0\n",
      "36ccbcf4-0720-48c3-829b-fb0928a1da35   |  b4aea466-6235-4a08-8ba8-4442261cdde0\n",
      "1a5908af-0d58-4434-b1c1-e236e532c651   |  b4c44950-2642-4ced-a46c-fbdf98998cd4\n",
      "5540392b-705d-43a6-a277-c8fdd38ff418   |  418b9971-1a7c-4671-8296-9210bf88453b\n",
      "5309a276-4b76-4548-a30d-5c876938f661   |  fdacbde1-fa3c-4eb1-ac99-51af4f3dc7f9\n",
      "0db88997-03cf-4fdc-92cb-54fdf693a81b   |  f1cfc7ba-1d3e-4f87-b3a7-39ec87465da1\n",
      "33dbd76d-6320-4a0e-a690-3b4e41f22af6   |  29b8162b-460f-4483-84ac-1f519aac273b\n",
      "29c1e006-7834-4612-95f0-1be000b506d7   |  bc83c2bc-7acf-48f3-9f1a-10925be2f3df\n",
      "53070c43-81e1-48b3-ba32-809b2e368cc8   |  eebc46a4-ca17-4b32-9e10-4f84724809d7\n",
      "29040ea9-e1d9-4d02-8361-6fbd29717bcc   |  859ad2ff-ffb9-494a-b20e-d082e422d32a\n",
      "1771c58e-9ee4-4985-9952-46e72ad9a0b9   |  4d168861-a083-43d8-80bf-4bc07f90e975\n",
      "1d7829db-55bd-444d-9c0d-73b359fca920   |  7f1ee9e4-8e63-4a7f-a74b-fc4aef7e9e2f\n",
      "070d4df1-312d-4eac-bd0a-fa92f5e7a944   |  5b544f6a-bf88-404e-8b2d-ead8c1ff24d4\n",
      "27122db9-22a4-465e-bd23-df5f86aaa074   |  9142fd72-50f8-4d6c-8464-3c4d4ed89cfd\n",
      "157203b7-ed05-4834-b29b-1d713d563988   |  069e5258-c44a-44a3-a5d0-3d0ea6abd6d5\n",
      "04ef3bc6-0429-4006-81a5-14da5433d4fb   |  ccbfe1b3-7f59-4107-9676-435db1537d08\n",
      "15770fa5-697b-49cd-8ee8-34e9da7a3c49   |  a7a300c2-fab7-478c-b3d9-03b2782384b4\n",
      "3ae99213-cd45-474a-bf43-e7df7590a41b   |  d297f2d0-dcb7-414e-b725-0220c4f80951\n",
      "024fef84-a06c-4b2a-ae5c-80983a842f17   |  8ae6f0c4-4fc4-40d2-8f2e-feba0629cfd0\n",
      "14702b40-6252-4794-b86e-84beb9bbb4c9   |  afb4da9b-9525-4995-bec2-144a3e4bb8f7\n",
      "1b47cfb3-7cd9-4072-afef-4720e1facee4   |  eed27df9-0d60-4a51-8f22-44b4e983bed8\n",
      "532ed034-febc-40c9-987c-fb1c805fd873   |  884872dd-4f26-4b9a-bd79-af50ffa2c95a\n",
      "1bc96263-6edc-4929-87a1-f02cc185c8d5   |  b14f5b18-69d6-4d39-a57e-fa030b499806\n",
      "28fad7e2-976f-4fe1-a565-b0100c8cda03   |  b34fbcfc-18cc-46da-8902-256bd0781334\n",
      "534f9acb-5daf-486a-b7fb-40d8c5a45fa1   |  80c9d5d8-d043-43ed-bba1-68bb905880ab\n",
      "1603f48c-ca03-406c-ac00-50db7ccac744   |  97506c3a-f9e6-41e9-b873-52ee83da2c0b\n",
      "0ac10e1c-80ca-4c54-a741-593e07476ce0   |  4a72f6ed-58b4-4e34-83e0-96d032631517\n",
      "82d7b9fe-1334-40fc-b128-269166c2eebc   |  06835df2-9ed2-456a-994b-0de14aa78b02\n",
      "456b47a2-3306-4342-a2bc-178478d04e65   |  d279219a-e5fd-4070-902d-98843c912ca8\n",
      "2bf5cc76-aab2-45c2-b78d-abe89f211e0d   |  0a51178d-7181-4106-ade6-ebc96971a963\n",
      "34ca92c3-d76c-4824-b5d4-e6eed3870a25   |  cc3c28b5-eed0-4288-8390-31b273a9b27c\n",
      "046c29f5-2ff5-4342-9214-3c4f0afc8b57   |  15158e48-26e0-4146-8d7a-b7428ac87588\n",
      "3ff5ec02-9531-47d6-a019-76c8cfbb7362   |  6a2d31aa-0c6b-4b42-9c32-8404a2869b3a\n",
      "1655cf5d-422c-4587-bcfe-d1ec045c7ef3   |  d7746f51-89f5-4ac9-8c0a-9a7a028798ba\n",
      "385b737f-b699-4c0b-96c3-d2b6da907be0   |  8f031a56-803c-41df-b670-627d3a1c70aa\n",
      "0d89a30f-31b9-4bb6-9a03-16140dfe7b2d   |  ecac7669-1bf8-482f-9f62-853331ce564a\n",
      "3e639f26-e9dd-47d0-bba7-de8a1decaeab   |  2ad35324-c87c-4f8a-99d8-349bba8977aa\n",
      "041ef04e-36b7-49e1-bbc5-cb6d3af3ee07   |  a1cae842-fb92-4686-ad94-4e3571bc6945\n",
      "4fd21b19-83f5-4676-8019-2601f639b2a2   |  d3395654-2a1a-481d-86e7-d28eeb467189\n",
      "5726090e-8049-411a-80d7-e3cd5a01557a   |  656bdd74-c78d-49f4-a96a-96ab1b3ffb61\n",
      "27756a7c-262a-4afb-9790-79fa5c737f8c   |  14b09965-85ac-42b2-95da-6910f0cb6c64\n",
      "536a9b68-f9a4-4be5-afe6-6e66037dca2c   |  53deab0e-c586-4bc9-936a-5643b4ba1121\n",
      "217fcfb5-9dcb-4fdf-8a34-ad57eb7e5a5d   |  6f3e6f54-7e13-4be6-a53f-5f3e91665059\n",
      "1b1708a4-6b6c-4fd9-a130-179593828a13   |  33ab389f-62f9-4b52-aeda-4c8c8f0d44dc\n",
      "40f39de4-2a67-4423-a42c-5eb7e43041bd   |  de78d3e9-1b9e-4098-a036-6e2134b2a90e\n",
      "2f53c1e3-f824-42ef-a983-c3d627571604   |  9de1b711-75ff-44d2-a664-2b1de2208fc6\n",
      "52729209-633e-4923-abe4-6579306298bb   |  421ce8e6-85a2-4cd2-9a27-e269ab6c0676\n",
      "0b02fc3d-5d23-4ec3-81d1-f0e157a26f02   |  8e4b1234-6f5d-4648-b2df-2109b44af530\n",
      "4e243ce9-b424-4a4d-b7a9-e03b8026876b   |  6aef4717-292b-48dd-9069-337c559c641e\n",
      "0a6188fc-9854-4029-810d-5ba61f544154   |  f4428232-b172-4dc8-92f2-6d28e3767658\n",
      "3debb701-03ac-4a4e-9062-cac24adde50c   |  0ff8b8bb-baf4-426e-b47b-00eb0eef79d1\n",
      "30c3ee7a-37ec-4975-8335-8324a81e2afd   |  16e6ada3-c0bb-49a6-be90-4da3db5f7fe1\n",
      "05b4e048-4c6c-4ae6-976c-55a645c5b592   |  4a09a9ce-b3f6-485f-beba-f69ea636fbbf\n",
      "1fe88546-2411-4768-9803-0b4bb756029c   |  015b841a-f904-4fdc-bc4f-39e8bda08c18\n",
      "1ca7c44d-9fe0-45f9-9873-9c909b9e8961   |  c14cf08a-e2ae-4216-acd2-09efcdebdc69\n",
      "1b29e833-8cb4-402f-b1aa-4a89f931f4e1   |  6081f718-5746-4186-a1aa-271d648d9c83\n",
      "04f17775-32de-43ec-9319-6d9eb7bc03ab   |  3a321ece-55eb-4896-b86f-48b7c4039a12\n",
      "1afe8335-0561-4cb5-9b02-3e88d89fa9ff   |  aec9a7cc-2b25-4de2-b5f6-44e9a909a792\n",
      "0830259c-406c-41d8-9147-b66ab5f8374f   |  c43a6a28-233c-403d-8a7c-749b99bb765e\n",
      "49b9ed7d-03c0-4e49-aac9-f0a18976aca7   |  e14c36db-a986-48e3-9c74-005c1d4b6ecf\n",
      "06e0d485-d4e1-4ba7-8eb2-e2f1fcfca416   |  933149f9-e660-4377-95c8-f8dd329db24e\n",
      "56cfa0d5-a050-4443-9a80-1403bcad6839   |  9f707190-3b32-48bf-a5f4-ceec6eedb847\n",
      "52f01d97-ae72-414c-aecb-9a23a6df6e9f   |  e0fe3e65-8aa6-4f38-bb83-85948d5539bc\n",
      "0574335c-9884-40de-a514-97b3fd3d72df   |  ef7e175e-2391-45a0-b69f-33837668bb79\n",
      "3c07e9ae-1796-4bcd-8b12-1ef8a9b61fd5   |  7ed53812-357f-4ad4-bccc-39bb63e27ccb\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "id": "394f2ec2d683ff52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T02:31:56.072011Z",
     "start_time": "2024-09-29T02:31:56.020799Z"
    }
   },
   "source": [
    "df_test['is_duplicate'] = False\n",
    "df_test['duplicate_for'] = None\n",
    "for i, j in d:\n",
    "    df_test.loc[j, 'is_duplicate'] = True\n",
    "    df_test.loc[j, 'duplicate_for'] = df_test.uuid[i]"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "id": "5b3c236b47478aae",
   "metadata": {},
   "source": [
    "df_test.to_csv('submission.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
